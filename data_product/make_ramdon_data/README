先实现向kafka发送随机数据
记录辅助命令
```shell
# 查看topic
/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server hadoop1:9092,hadoop2:9092,hadoop3:9092

# 创建topic
/opt/kafka/bin/kafka-topics.sh --create --topic test --partitions 3 --replication-factor 2 --bootstrap-server hadoop1:9092,hadoop2:9092,hadoop3:9092

#建立生产者
/opt/kafka/bin/kafka-console-producer.sh --topic test --broker-list hadoop1:9092,hadoop2:9092,hadoop3:9092

#建立消费者
#/opt/kafka/bin/kafka-console-consumer.sh --topic sale_random_data --from-beginning --bootstrap-server hadoop1:9092,hadoop2:9092,hadoop3:9092
/opt/kafka/bin/kafka-console-consumer.sh --topic person_random_data --bootstrap-server hadoop1:9092,hadoop2:9092,hadoop3:9092

#测试通过生产者数据数据消费者会打印出来

后续处理见ProcessOnFlink

数据生成器，需要修改。加入tm字段这样就可自动塞入。flink中了。生成策略
sale_data,每1000条过去10秒，10+±5秒随机。
其他数据以sale_data为基准。在送入kafka时才定tm字段，在sale_data的tm中用正太随机函数，方差为1秒。